---
title: "Hackaton"
author: "Ibrahim&Thomas"
date: "`r format(Sys.time())`" # remove the # to show the date
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    theme: spacelab
    highlight: zenburn
    df_print: paged
editor_options: 
  chunk_output_type: inline
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r}
set.seed(704195)
```

```{r}
library(corrplot) # used to visualize the correlations between the columns of our dataset
library(randomForest) # used for Random Forest model
library(gbm) # used for Boosting model
```


```{r}
library(MLmetrics)
```


# Read the dataset

```{r}

train <- read.csv("data.csv")
test <- read.csv("test.csv")

```


```{r}
train <- subset(train,select = -c(month,day_of_week,job,education,marital,contact,previous))
train = na.omit(train)
```


## Mapping binary categorical values
```{r}
train$default = ifelse(train$default == "no", 1,ifelse(train$default == "yes", -1,0))
train$housing = ifelse(train$housing == "yes", 1,ifelse(train$housing == "no", 0,-1))
train$loan = ifelse(train$loan == "yes", 1,ifelse(train$loan == "no", 0,-1))
train$poutcome = ifelse(train$poutcome == "success",1,ifelse(train$poutcome == "failure",0,-1))
train$y = ifelse(train$y == 'yes',1,0)

```

```{r}
test$default = ifelse(test$default == "no", 1,ifelse(test$default == "yes", -1,0))
test$housing = ifelse(test$housing == "yes", 1,ifelse(test$housing == "no", 0,-1))
test$loan = ifelse(test$loan == "yes", 1,ifelse(test$loan == "no", 0,-1))
test$poutcome = ifelse(test$poutcome == "success",1,ifelse(test$poutcome == "failure",0,-1))
```

```{r}
M<-cor(train)
```

```{r}
corrplot(M,method="circle")
```

```{r}

```


```{r}
library(caTools)
split = sample.split(train$y, SplitRatio = 0.75)
training_set = subset(train, split == TRUE)
test_set = subset(train, split == FALSE)
```


# EDA : Exploratory Data Analysis of the training set 

```{r}

summary(train)
str(train)
names(train)
dim(train)
head(train)


```



# Preprocessing, cleaning of the dataset

```{r}

#verify that there are no nan values

#keep columns that are numeric
```




# Logistic Regression 


## 1)

## test model
```{r}
model_glm = glm(y~.,data=training_set,family="binomial")
pred_glm = predict(model_glm,test_set)
predicted_vect = ifelse(pred_glm > 0.39,1,0)
```

```{r}
F1_Score(test_set$y,predicted_vect)
```


```{r}
model_glm = glm(y~.,data=train,family="binomial")
pred_glm = predict(model_glm,test)
predicted_vect = ifelse(pred_glm > 0.35,1,0)
```




# Algo 2 


## 1)

```{r}
boost <- gbm(y ~ ., data = training_set, distribution = "bernoulli",
            n.trees = 5000, interaction.depth = 6, shrinkage = 0.001)
boost.pred <- predict(boost, newdata = test_set, type = "response")
boost.pred <- ifelse(boost.pred >0.5, 1, 0)
```

```{r}
boost <- gbm(y ~ ., data = train, distribution = "bernoulli",
            n.trees = 5000, interaction.depth = 5, shrinkage = 0.001)
boost.pred <- predict(boost, newdata = test, type = "response")
predicted_vect <- ifelse(boost.pred >0.4, 1, 0)
```



```{r}
F1_Score(test_set$y,boost.pred)
```

```{r}
F1_Score(test_set$y,boost.pred)
```


# Algo 3 


## 1)
```{r}
p = (dim(train)[2]-1)/3
bagging <- randomForest(y ~ ., data = training_set, mtry = p)
bagging.pred <- predict(bagging, newdata = test_set, type = "response")
bagging.pred <- ifelse(bagging.pred > 0.5, 1, 0)
```

```{r}
F1_Score(test_set$y,bagging.pred)
```


```{r}
predicted_vect = ifelse(predicted_vect>0,'yes','no')
to_be_submitted = data.frame(id = rownames(test), y = predicted_vect)
write.csv(to_be_submitted , file = "BoostFinal.csv", row.names = F)
```


```{r}
ttt = read.csv('BoostFinal.csv')
```





